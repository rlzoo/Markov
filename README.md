![MDP Image](https://cdn-images-1.medium.com/max/1200/1*QuBOz2yQ5Fy6YnZyvSPXzw.png)

## Markov: Simple Python Library for Markov Decision Processes
#### Author: Stephen Offer

Markov is an easy to use collection of functions and objects to create MDP 
functions.

Markov allows for synchronous and asynchronous execution to experiment with 
the performance advantages of distributed systems.

It is split into three main sections:

#### States:

- Reward, Terminal, Actions, Values, Previous States, Next States, State 
Policy Probabilities.

#### Policies:

- Greedy-Policy
- More to come...

#### Optimizers:

- Value/Policy Iteration

#### Contributors Welcome

